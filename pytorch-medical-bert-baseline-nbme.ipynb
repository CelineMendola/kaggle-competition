{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NBME - Score Clinical Patient Notes \n- **Framework:** Pytorch\n- **Model Architecture:**\n    - BERT\n    - Linear(768, 512)\n    - Linear(512, 1)\n- **LR:** 1e-5\n- **Batch Size:** 8\n- **Epoch:** 6\n- **Dropout:** 0.2\n- **Criterion:** BCEWithLogitsLoss\n- **Optimizer:** AdamW\n\n# Tokenizer params\n- **Max Lenght:** 416\n- **Padding:** max_lenght\n- **Truncation:** only_scond\n","metadata":{}},{"cell_type":"code","source":"from ast import literal_eval\nfrom itertools import chain\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.model_selection import train_test_split\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom tqdm.notebook import tqdm\nfrom transformers import AutoModel, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:41:37.672925Z","iopub.execute_input":"2022-03-22T07:41:37.673328Z","iopub.status.idle":"2022-03-22T07:41:37.679794Z","shell.execute_reply.started":"2022-03-22T07:41:37.673290Z","shell.execute_reply":"2022-03-22T07:41:37.679207Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Helper Functions\n### 1. Datasets Helper Function\nneed to merge `features.csv`, `patient_notes.csv` with `train.csv`","metadata":{}},{"cell_type":"code","source":"BASE_URL = \"../input/nbme-score-clinical-patient-notes\"\n\n\ndef process_feature_text(text):\n    return text.replace(\"-OR-\", \";-\").replace(\"-\", \" \")\n\n\ndef prepare_datasets():\n    features = pd.read_csv(f\"{BASE_URL}/features.csv\")\n    notes = pd.read_csv(f\"{BASE_URL}/patient_notes.csv\")\n    df = pd.read_csv(f\"{BASE_URL}/train.csv\")\n    df[\"annotation_list\"] = [literal_eval(x) for x in df[\"annotation\"]]\n    df[\"location_list\"] = [literal_eval(x) for x in df[\"location\"]]\n\n    merged = df.merge(notes, how=\"left\")\n    merged = merged.merge(features, how=\"left\")\n\n    merged[\"feature_text\"] = [process_feature_text(x) for x in merged[\"feature_text\"]]\n    merged[\"feature_text\"] = merged[\"feature_text\"].apply(lambda x: x.lower())\n    merged[\"pn_history\"] = merged[\"pn_history\"].apply(lambda x: x.lower())\n\n    return merged","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:41:39.375216Z","iopub.execute_input":"2022-03-22T07:41:39.375834Z","iopub.status.idle":"2022-03-22T07:41:39.386245Z","shell.execute_reply.started":"2022-03-22T07:41:39.375795Z","shell.execute_reply":"2022-03-22T07:41:39.385430Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### 2. Tokenizer Helper Function","metadata":{}},{"cell_type":"code","source":"def loc_list_to_ints(loc_list):\n    to_return = []\n    for loc_str in loc_list:\n        loc_strs = loc_str.split(\";\")\n        for loc in loc_strs:\n            start, end = loc.split()\n            to_return.append((int(start), int(end)))\n    return to_return\n\n\ndef tokenize_and_add_labels(tokenizer, data, config):\n    out = tokenizer(\n        data[\"feature_text\"],\n        data[\"pn_history\"],\n        truncation=config['truncation'],\n        max_length=config['max_length'],\n        padding=config['padding'],\n        return_offsets_mapping=config['return_offsets_mapping']\n    )\n    labels = [0.0] * len(out[\"input_ids\"])\n    out[\"location_int\"] = loc_list_to_ints(data[\"location_list\"])\n    out[\"sequence_ids\"] = out.sequence_ids()\n\n    for idx, (seq_id, offsets) in enumerate(zip(out[\"sequence_ids\"], out[\"offset_mapping\"])):\n        if not seq_id or seq_id == 0:\n            labels[idx] = -1\n            continue\n\n        token_start, token_end = offsets\n        for feature_start, feature_end in out[\"location_int\"]:\n            if token_start >= feature_start and token_end <= feature_end:\n                labels[idx] = 1.0\n                break\n\n    out[\"labels\"] = labels\n\n    return out","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:41:40.098102Z","iopub.execute_input":"2022-03-22T07:41:40.098680Z","iopub.status.idle":"2022-03-22T07:41:40.108576Z","shell.execute_reply.started":"2022-03-22T07:41:40.098641Z","shell.execute_reply":"2022-03-22T07:41:40.107603Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### 3. Prediction and Score Helper Function","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ndef get_location_predictions(preds, offset_mapping, sequence_ids, test=False):\n    all_predictions = []\n    for pred, offsets, seq_ids in zip(preds, offset_mapping, sequence_ids):\n        pred = 1 / (1 + np.exp(-pred))\n        start_idx = None\n        end_idx = None\n        current_preds = []\n        for pred, offset, seq_id in zip(pred, offsets, seq_ids):\n            if seq_id is None or seq_id == 0:\n                continue\n\n            if pred > 0.5:\n                if start_idx is None:\n                    start_idx = offset[0]\n                end_idx = offset[1]\n            elif start_idx is not None:\n                if test:\n                    current_preds.append(f\"{start_idx} {end_idx}\")\n                else:\n                    current_preds.append((start_idx, end_idx))\n                start_idx = None\n        if test:\n            all_predictions.append(\"; \".join(current_preds))\n        else:\n            all_predictions.append(current_preds)\n            \n    return all_predictions\n\n\ndef calculate_char_cv(predictions, offset_mapping, sequence_ids, labels):\n    all_labels = []\n    all_preds = []\n    for preds, offsets, seq_ids, labels in zip(predictions, offset_mapping, sequence_ids, labels):\n\n        num_chars = max(list(chain(*offsets)))\n        char_labels = np.zeros(num_chars)\n\n        for o, s_id, label in zip(offsets, seq_ids, labels):\n            if s_id is None or s_id == 0:\n                continue\n            if int(label) == 1:\n                char_labels[o[0]:o[1]] = 1\n\n        char_preds = np.zeros(num_chars)\n\n        for start_idx, end_idx in preds:\n            char_preds[start_idx:end_idx] = 1\n\n        all_labels.extend(char_labels)\n        all_preds.extend(char_preds)\n\n    results = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\", labels=np.unique(all_preds))\n    accuracy = accuracy_score(all_labels, all_preds)\n    \n\n    return {\n        \"Accuracy\": accuracy,\n        \"precision\": results[0],\n        \"recall\": results[1],\n        \"f1\": results[2]\n    }","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:41:48.193446Z","iopub.execute_input":"2022-03-22T07:41:48.193713Z","iopub.status.idle":"2022-03-22T07:41:48.210701Z","shell.execute_reply.started":"2022-03-22T07:41:48.193684Z","shell.execute_reply":"2022-03-22T07:41:48.209897Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data, tokenizer, config):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        data = self.data.iloc[idx]\n        tokens = tokenize_and_add_labels(self.tokenizer, data, self.config)\n\n        input_ids = np.array(tokens[\"input_ids\"])\n        attention_mask = np.array(tokens[\"attention_mask\"])\n        token_type_ids = np.array(tokens[\"token_type_ids\"])\n\n        labels = np.array(tokens[\"labels\"])\n        offset_mapping = np.array(tokens['offset_mapping'])\n        sequence_ids = np.array(tokens['sequence_ids']).astype(\"float16\")\n        \n        return input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:41:50.513407Z","iopub.execute_input":"2022-03-22T07:41:50.516110Z","iopub.status.idle":"2022-03-22T07:41:50.527789Z","shell.execute_reply.started":"2022-03-22T07:41:50.516062Z","shell.execute_reply":"2022-03-22T07:41:50.526948Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Model\n- Lets use **BERT** base Architecture\n- Also Used 3 FC layers\n\n**Comments:** 3 layers improve accuracy 2% on public score","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass CustomModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(config['model_name'])  # BERT model\n        self.dropout = nn.Dropout(p=config['dropout'])\n        self.config = config\n        self.fc1 = nn.Linear(768, 512)\n        #self.fc2 = nn.Linear(512, 512)\n        self.fc2 = nn.Linear(512, 1)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        logits = F.relu(self.fc1(outputs[0]))\n        #logits = self.fc2(self.dropout(logits))\n        logits = self.fc2(self.dropout(logits)).squeeze(-1)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:41:52.841098Z","iopub.execute_input":"2022-03-22T07:41:52.841359Z","iopub.status.idle":"2022-03-22T07:41:52.848661Z","shell.execute_reply.started":"2022-03-22T07:41:52.841332Z","shell.execute_reply":"2022-03-22T07:41:52.847789Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameters\n","metadata":{}},{"cell_type":"code","source":"hyperparameters = {\n    \"max_length\": 416,\n    \"padding\": \"max_length\",\n    \"return_offsets_mapping\": True,\n    \"truncation\": \"only_second\",\n    \"model_name\": \"../input/layoutlm/Bio_ClinicalBERT\",\n    \"dropout\": 0.2,\n    \"lr\": 1e-5,\n    \"test_size\": 0.2,\n    \"seed\": 1268,\n    \"batch_size\": 8\n}","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:41:56.768213Z","iopub.execute_input":"2022-03-22T07:41:56.768496Z","iopub.status.idle":"2022-03-22T07:41:56.773334Z","shell.execute_reply.started":"2022-03-22T07:41:56.768467Z","shell.execute_reply":"2022-03-22T07:41:56.772609Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Datasets\nTrain and Test split: 20%\n\nTotal Data:\n- Train: 11440\n- Test: 2860","metadata":{}},{"cell_type":"code","source":"train_df = prepare_datasets()\n\nX_train, X_test = train_test_split(train_df, test_size=hyperparameters['test_size'],\n                                   random_state=hyperparameters['seed'])\n\n\nprint(\"Train size\", len(X_train))\nprint(\"Test Size\", len(X_test))","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:41:58.977790Z","iopub.execute_input":"2022-03-22T07:41:58.978074Z","iopub.status.idle":"2022-03-22T07:42:00.093711Z","shell.execute_reply.started":"2022-03-22T07:41:58.978040Z","shell.execute_reply":"2022-03-22T07:42:00.092836Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Train size 11440\nTest Size 2860\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(hyperparameters['model_name'])\n\ntraining_data = CustomDataset(X_train, tokenizer, hyperparameters)\ntrain_dataloader = DataLoader(training_data, batch_size=hyperparameters['batch_size'], shuffle=True)\n\ntest_data = CustomDataset(X_test, tokenizer, hyperparameters)\ntest_dataloader = DataLoader(test_data, batch_size=hyperparameters['batch_size'], shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:42:02.134289Z","iopub.execute_input":"2022-03-22T07:42:02.134535Z","iopub.status.idle":"2022-03-22T07:42:02.199090Z","shell.execute_reply.started":"2022-03-22T07:42:02.134507Z","shell.execute_reply":"2022-03-22T07:42:02.198352Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Train\nLets train the model\nwith BCEWithLogitsLoss and AdamW as optimizer\n\n**Notes:** on BCEWithLogitsLoss, the default value for reduction is `mean` (the sum of the output will be divided by the number of elements in the output). If we use this default value, it will produce negative loss. Because we have some negative labels. To fix this negative loss issue, we can use `none` as parameter. To calculate the mean, first, we have to filter out the negative values. [DOC](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)","metadata":{}},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = CustomModel(hyperparameters).to(DEVICE)\n\ncriterion = torch.nn.BCEWithLogitsLoss(reduction = \"none\")\noptimizer = optim.AdamW(model.parameters(), lr=hyperparameters['lr'])","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:42:06.625770Z","iopub.execute_input":"2022-03-22T07:42:06.626041Z","iopub.status.idle":"2022-03-22T07:42:16.315280Z","shell.execute_reply.started":"2022-03-22T07:42:06.626011Z","shell.execute_reply":"2022-03-22T07:42:16.314570Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train_model(model, dataloader, optimizer, criterion):\n        model.train()\n        train_loss = []\n\n        for batch in tqdm(dataloader):\n            optimizer.zero_grad()\n            input_ids = batch[0].to(DEVICE)\n            attention_mask = batch[1].to(DEVICE)\n            token_type_ids = batch[2].to(DEVICE)\n            labels = batch[3].to(DEVICE)\n\n            logits = model(input_ids, attention_mask, token_type_ids)\n            loss = criterion(logits, labels)\n            # since, we have\n            loss = torch.masked_select(loss, labels > -1.0).mean()\n            train_loss.append(loss.item() * input_ids.size(0))\n            loss.backward()\n            # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n            # it's also improve f1 accuracy slightly\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n        return sum(train_loss)/len(train_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:42:18.185562Z","iopub.execute_input":"2022-03-22T07:42:18.185838Z","iopub.status.idle":"2022-03-22T07:42:18.193469Z","shell.execute_reply.started":"2022-03-22T07:42:18.185809Z","shell.execute_reply":"2022-03-22T07:42:18.192676Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, dataloader, criterion):\n        model.eval()\n        valid_loss = []\n        preds = []\n        offsets = []\n        seq_ids = []\n        valid_labels = []\n\n        for batch in tqdm(dataloader):\n            input_ids = batch[0].to(DEVICE)\n            attention_mask = batch[1].to(DEVICE)\n            token_type_ids = batch[2].to(DEVICE)\n            labels = batch[3].to(DEVICE)\n            offset_mapping = batch[4]\n            sequence_ids = batch[5]\n\n            logits = model(input_ids, attention_mask, token_type_ids)\n            loss = criterion(logits, labels)\n            loss = torch.masked_select(loss, labels > -1.0).mean()\n            valid_loss.append(loss.item() * input_ids.size(0))\n\n            preds.append(logits.detach().cpu().numpy())\n            offsets.append(offset_mapping.numpy())\n            seq_ids.append(sequence_ids.numpy())\n            valid_labels.append(labels.detach().cpu().numpy())\n\n        preds = np.concatenate(preds, axis=0)\n        offsets = np.concatenate(offsets, axis=0)\n        seq_ids = np.concatenate(seq_ids, axis=0)\n        valid_labels = np.concatenate(valid_labels, axis=0)\n        location_preds = get_location_predictions(preds, offsets, seq_ids, test=False)\n        score = calculate_char_cv(location_preds, offsets, seq_ids, valid_labels)\n\n        return sum(valid_loss)/len(valid_loss), score","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:42:18.442073Z","iopub.execute_input":"2022-03-22T07:42:18.442684Z","iopub.status.idle":"2022-03-22T07:42:18.455192Z","shell.execute_reply.started":"2022-03-22T07:42:18.442652Z","shell.execute_reply":"2022-03-22T07:42:18.454245Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import time\n\ntrain_loss_data, valid_loss_data = [], []\nscore_data_list = []\nvalid_loss_min = np.Inf\nsince = time.time()\nepochs = 6","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:42:20.762384Z","iopub.execute_input":"2022-03-22T07:42:20.762728Z","iopub.status.idle":"2022-03-22T07:42:20.772719Z","shell.execute_reply.started":"2022-03-22T07:42:20.762682Z","shell.execute_reply":"2022-03-22T07:42:20.771826Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"best_loss = np.inf\n\nfor i in range(epochs):\n    print(\"Epoch: {}/{}\".format(i + 1, epochs))\n    # first train model\n    train_loss = train_model(model, train_dataloader, optimizer, criterion)\n    train_loss_data.append(train_loss)\n    print(f\"Train loss: {train_loss}\")\n    # evaluate model\n    valid_loss, score = eval_model(model, test_dataloader, criterion)\n    valid_loss_data.append(valid_loss)\n    score_data_list.append(score)\n    print(f\"Valid loss: {valid_loss}\")\n    print(f\"Valid score: {score}\")\n    \n    if valid_loss < best_loss:\n        best_loss = valid_loss\n        torch.save(model.state_dict(), \"nbme_bert_v2.pth\")\n\n    \ntime_elapsed = time.time() - since\nprint('Training completed in {:.0f}m {:.0f}s'.format(\n    time_elapsed // 60, time_elapsed % 60))","metadata":{"execution":{"iopub.status.busy":"2022-03-22T07:42:28.763314Z","iopub.execute_input":"2022-03-22T07:42:28.763855Z","iopub.status.idle":"2022-03-22T08:45:31.001245Z","shell.execute_reply.started":"2022-03-22T07:42:28.763816Z","shell.execute_reply":"2022-03-22T08:45:30.999904Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch: 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"516c6dfdd8c94a0195ae24a4bf921a28"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.328589380187641\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a558166be004ec0acf0477436a8817a"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.15927041361386146\nValid score: {'Accuracy': 0.9917994380763949, 'precision': 0.7028457103746019, 'recall': 0.7718035440696095, 'f1': 0.7357123174428217}\nEpoch: 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a73ac97f9a2f4f5b9272ffbb25864ab0"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.1313076347543845\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1badfc530094a62b4337cb17a628e88"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.13309523479756868\nValid score: {'Accuracy': 0.9930892459860767, 'precision': 0.7535916772169318, 'recall': 0.7915185153065649, 'f1': 0.7720896132643422}\nEpoch: 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d89fcfc1e8a9440094beae33fe8d76da"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.09480805930808589\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"726ee5c747e5498b8289e066431d0ca5"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.12655945591869083\nValid score: {'Accuracy': 0.992744242677123, 'precision': 0.7097688150282137, 'recall': 0.8617639406816407, 'f1': 0.778416063921456}\nEpoch: 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef9f3bed995b4a6c8fb9aa4a7a8864a5"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.07284329530048449\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cd8a8f5a74f449ebab2f230d2296775"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.12064726110789091\nValid score: {'Accuracy': 0.9933367762411996, 'precision': 0.738583586473527, 'recall': 0.8504610759402191, 'f1': 0.7905839357213877}\nEpoch: 5/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"251c7c905dde432da8a29cfe4b420477"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.05843109389717797\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f015277d3eac4edb97e389af16b23148"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.11937118623876755\nValid score: {'Accuracy': 0.9934158662190886, 'precision': 0.7359362706530291, 'recall': 0.8652617581591652, 'f1': 0.7953763369428022}\nEpoch: 6/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0e3808229964c6ca1e08731de7cfef8"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.046987863728737915\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d072521bbaf4797abe2a744027cfab5"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.1349057223943351\nValid score: {'Accuracy': 0.9939258896981242, 'precision': 0.7787806679248379, 'recall': 0.8230855953516607, 'f1': 0.8003204317396071}\nTraining completed in 63m 10s\n","output_type":"stream"}]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nplt.plot(train_loss_data, label=\"Training loss\")\nplt.plot(valid_loss_data, label=\"validation loss\")\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T08:45:31.003277Z","iopub.execute_input":"2022-03-22T08:45:31.003590Z","iopub.status.idle":"2022-03-22T08:45:31.249844Z","shell.execute_reply.started":"2022-03-22T08:45:31.003541Z","shell.execute_reply":"2022-03-22T08:45:31.249113Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x7f77837e3f50>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"import pandas as pd\n\nscore_df = pd.DataFrame.from_dict(score_data_list)\nscore_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T08:45:31.250972Z","iopub.execute_input":"2022-03-22T08:45:31.251837Z","iopub.status.idle":"2022-03-22T08:45:31.268398Z","shell.execute_reply.started":"2022-03-22T08:45:31.251797Z","shell.execute_reply":"2022-03-22T08:45:31.267659Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   Accuracy  precision    recall        f1\n0  0.991799   0.702846  0.771804  0.735712\n1  0.993089   0.753592  0.791519  0.772090\n2  0.992744   0.709769  0.861764  0.778416\n3  0.993337   0.738584  0.850461  0.790584\n4  0.993416   0.735936  0.865262  0.795376","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.991799</td>\n      <td>0.702846</td>\n      <td>0.771804</td>\n      <td>0.735712</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.993089</td>\n      <td>0.753592</td>\n      <td>0.791519</td>\n      <td>0.772090</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.992744</td>\n      <td>0.709769</td>\n      <td>0.861764</td>\n      <td>0.778416</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.993337</td>\n      <td>0.738584</td>\n      <td>0.850461</td>\n      <td>0.790584</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.993416</td>\n      <td>0.735936</td>\n      <td>0.865262</td>\n      <td>0.795376</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Prepare For Testing","metadata":{}},{"cell_type":"markdown","source":"Load best model","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"nbme_bert_v2.pth\", map_location = DEVICE))","metadata":{"execution":{"iopub.status.busy":"2022-03-22T08:45:31.270619Z","iopub.execute_input":"2022-03-22T08:45:31.270914Z","iopub.status.idle":"2022-03-22T08:45:31.522922Z","shell.execute_reply.started":"2022-03-22T08:45:31.270878Z","shell.execute_reply":"2022-03-22T08:45:31.522080Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"def create_test_df():\n    feats = pd.read_csv(f\"{BASE_URL}/features.csv\")\n    notes = pd.read_csv(f\"{BASE_URL}/patient_notes.csv\")\n    test = pd.read_csv(f\"{BASE_URL}/test.csv\")\n\n    merged = test.merge(notes, how = \"left\")\n    merged = merged.merge(feats, how = \"left\")\n\n    def process_feature_text(text):\n        return text.replace(\"-OR-\", \";-\").replace(\"-\", \" \")\n    \n    merged[\"feature_text\"] = [process_feature_text(x) for x in merged[\"feature_text\"]]\n    \n    return merged\n\n\nclass SubmissionDataset(Dataset):\n    def __init__(self, data, tokenizer, config):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        example = self.data.loc[idx]\n        tokenized = self.tokenizer(\n            example[\"feature_text\"],\n            example[\"pn_history\"],\n            truncation = self.config['truncation'],\n            max_length = self.config['max_length'],\n            padding = self.config['padding'],\n            return_offsets_mapping = self.config['return_offsets_mapping']\n        )\n        tokenized[\"sequence_ids\"] = tokenized.sequence_ids()\n\n        input_ids = np.array(tokenized[\"input_ids\"])\n        attention_mask = np.array(tokenized[\"attention_mask\"])\n        token_type_ids = np.array(tokenized[\"token_type_ids\"])\n        offset_mapping = np.array(tokenized[\"offset_mapping\"])\n        sequence_ids = np.array(tokenized[\"sequence_ids\"]).astype(\"float16\")\n\n        return input_ids, attention_mask, token_type_ids, offset_mapping, sequence_ids\n\n\ntest_df = create_test_df()\n\nsubmission_data = SubmissionDataset(test_df, tokenizer, hyperparameters)\nsubmission_dataloader = DataLoader(submission_data, batch_size=hyperparameters['batch_size'], shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T08:45:31.524426Z","iopub.execute_input":"2022-03-22T08:45:31.524697Z","iopub.status.idle":"2022-03-22T08:45:31.841161Z","shell.execute_reply.started":"2022-03-22T08:45:31.524661Z","shell.execute_reply":"2022-03-22T08:45:31.840493Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model.eval()\npreds = []\noffsets = []\nseq_ids = []\n\nfor batch in tqdm(submission_dataloader):\n    input_ids = batch[0].to(DEVICE)\n    attention_mask = batch[1].to(DEVICE)\n    token_type_ids = batch[2].to(DEVICE)\n    offset_mapping = batch[3]\n    sequence_ids = batch[4]\n\n    logits = model(input_ids, attention_mask, token_type_ids)\n    \n    preds.append(logits.detach().cpu().numpy())\n    offsets.append(offset_mapping.numpy())\n    seq_ids.append(sequence_ids.numpy())\n\npreds = np.concatenate(preds, axis=0)\noffsets = np.concatenate(offsets, axis=0)\nseq_ids = np.concatenate(seq_ids, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T08:45:31.842564Z","iopub.execute_input":"2022-03-22T08:45:31.842981Z","iopub.status.idle":"2022-03-22T08:45:31.981861Z","shell.execute_reply.started":"2022-03-22T08:45:31.842938Z","shell.execute_reply":"2022-03-22T08:45:31.981111Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ac8d1f93b14549bdd74c88141b28d4"}},"metadata":{}}]},{"cell_type":"code","source":"location_preds = get_location_predictions(preds, offsets, seq_ids, test=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T08:45:31.983133Z","iopub.execute_input":"2022-03-22T08:45:31.983437Z","iopub.status.idle":"2022-03-22T08:45:32.000461Z","shell.execute_reply.started":"2022-03-22T08:45:31.983402Z","shell.execute_reply":"2022-03-22T08:45:31.999718Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"len(location_preds), len(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T08:45:32.001673Z","iopub.execute_input":"2022-03-22T08:45:32.001979Z","iopub.status.idle":"2022-03-22T08:45:32.010909Z","shell.execute_reply.started":"2022-03-22T08:45:32.001943Z","shell.execute_reply":"2022-03-22T08:45:32.010066Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(5, 5)"},"metadata":{}}]},{"cell_type":"code","source":"test_df[\"location\"] = location_preds","metadata":{"execution":{"iopub.status.busy":"2022-03-22T08:45:32.012263Z","iopub.execute_input":"2022-03-22T08:45:32.012555Z","iopub.status.idle":"2022-03-22T08:45:32.018822Z","shell.execute_reply.started":"2022-03-22T08:45:32.012520Z","shell.execute_reply":"2022-03-22T08:45:32.018188Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_df[[\"id\", \"location\"]].to_csv(\"submission.csv\", index = False)\npd.read_csv(\"submission.csv\").head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T08:45:32.021480Z","iopub.execute_input":"2022-03-22T08:45:32.021734Z","iopub.status.idle":"2022-03-22T08:45:32.037898Z","shell.execute_reply.started":"2022-03-22T08:45:32.021701Z","shell.execute_reply":"2022-03-22T08:45:32.037277Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"          id        location\n0  00016_000    696 724; 0 0\n1  00016_001    668 693; 0 0\n2  00016_002         203 217\n3  00016_003  70 91; 176 183\n4  00016_004         222 258","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00016_000</td>\n      <td>696 724; 0 0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00016_001</td>\n      <td>668 693; 0 0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00016_002</td>\n      <td>203 217</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00016_003</td>\n      <td>70 91; 176 183</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00016_004</td>\n      <td>222 258</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Special Credits\n- [tomohiroh](https://www.kaggle.com/tomohiroh/nbme-bert-for-beginners)\n- [gazu468](https://www.kaggle.com/gazu468/nbme-details-eda)\n","metadata":{}}]}