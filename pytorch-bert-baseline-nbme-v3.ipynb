{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NBME - Score Clinical Patient Notes \n- **Framework:** Pytorch\n- **Model Architecture:**\n    - BERT\n    - Linear(768, 512)\n    - Linear(512, 512)\n    - Linear(512, 1)\n- **LR:** 1e-5\n- **Batch Size:** 8\n- **Epoch:** 3\n- **Dropout:** 0.2\n- **Criterion:** BCEWithLogitsLoss\n- **Optimizer:** AdamW\n\n# Tokenizer params\n- **Max Lenght:** 416\n- **Padding:** max_lenght\n- **Truncation:** only_scond\n","metadata":{}},{"cell_type":"code","source":"from ast import literal_eval\nfrom itertools import chain\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.model_selection import train_test_split\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom tqdm.notebook import tqdm\nfrom transformers import AutoModel, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:20.157990Z","iopub.execute_input":"2022-03-17T12:14:20.158522Z","iopub.status.idle":"2022-03-17T12:14:27.541035Z","shell.execute_reply.started":"2022-03-17T12:14:20.158343Z","shell.execute_reply":"2022-03-17T12:14:27.540306Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Helper Functions\n### 1. Datasets Helper Function\nneed to merge `features.csv`, `patient_notes.csv` with `train.csv`","metadata":{}},{"cell_type":"code","source":"BASE_URL = \"../input/nbme-score-clinical-patient-notes\"\n\n\ndef process_feature_text(text):\n    return text.replace(\"-OR-\", \";-\").replace(\"-\", \" \")\n\n\ndef prepare_datasets():\n    features = pd.read_csv(f\"{BASE_URL}/features.csv\")\n    notes = pd.read_csv(f\"{BASE_URL}/patient_notes.csv\")\n    df = pd.read_csv(f\"{BASE_URL}/train.csv\")\n    df[\"annotation_list\"] = [literal_eval(x) for x in df[\"annotation\"]]\n    df[\"location_list\"] = [literal_eval(x) for x in df[\"location\"]]\n\n    merged = df.merge(notes, how=\"left\")\n    merged = merged.merge(features, how=\"left\")\n\n    merged[\"feature_text\"] = [process_feature_text(x) for x in merged[\"feature_text\"]]\n    merged[\"feature_text\"] = merged[\"feature_text\"].apply(lambda x: x.lower())\n    merged[\"pn_history\"] = merged[\"pn_history\"].apply(lambda x: x.lower())\n\n    return merged","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:27.542761Z","iopub.execute_input":"2022-03-17T12:14:27.543086Z","iopub.status.idle":"2022-03-17T12:14:27.553509Z","shell.execute_reply.started":"2022-03-17T12:14:27.543046Z","shell.execute_reply":"2022-03-17T12:14:27.550839Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### 2. Tokenizer Helper Function","metadata":{}},{"cell_type":"code","source":"def loc_list_to_ints(loc_list):\n    to_return = []\n    for loc_str in loc_list:\n        loc_strs = loc_str.split(\";\")\n        for loc in loc_strs:\n            start, end = loc.split()\n            to_return.append((int(start), int(end)))\n    return to_return\n\n\ndef tokenize_and_add_labels(tokenizer, data, config):\n    out = tokenizer(\n        data[\"feature_text\"],\n        data[\"pn_history\"],\n        truncation=config['truncation'],\n        max_length=config['max_length'],\n        padding=config['padding'],\n        return_offsets_mapping=config['return_offsets_mapping']\n    )\n    labels = [0.0] * len(out[\"input_ids\"])\n    out[\"location_int\"] = loc_list_to_ints(data[\"location_list\"])\n    out[\"sequence_ids\"] = out.sequence_ids()\n\n    for idx, (seq_id, offsets) in enumerate(zip(out[\"sequence_ids\"], out[\"offset_mapping\"])):\n        if not seq_id or seq_id == 0:\n            labels[idx] = -1\n            continue\n\n        token_start, token_end = offsets\n        for feature_start, feature_end in out[\"location_int\"]:\n            if token_start >= feature_start and token_end <= feature_end:\n                labels[idx] = 1.0\n                break\n\n    out[\"labels\"] = labels\n\n    return out","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:27.554697Z","iopub.execute_input":"2022-03-17T12:14:27.555075Z","iopub.status.idle":"2022-03-17T12:14:27.568397Z","shell.execute_reply.started":"2022-03-17T12:14:27.555038Z","shell.execute_reply":"2022-03-17T12:14:27.567613Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### 3. Predection and Score Helper Function","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ndef get_location_predictions(preds, offset_mapping, sequence_ids, test=False):\n    all_predictions = []\n    for pred, offsets, seq_ids in zip(preds, offset_mapping, sequence_ids):\n        pred = 1 / (1 + np.exp(-pred))\n        start_idx = None\n        end_idx = None\n        current_preds = []\n        for pred, offset, seq_id in zip(pred, offsets, seq_ids):\n            if seq_id is None or seq_id == 0:\n                continue\n\n            if pred > 0.5:\n                if start_idx is None:\n                    start_idx = offset[0]\n                end_idx = offset[1]\n            elif start_idx is not None:\n                if test:\n                    current_preds.append(f\"{start_idx} {end_idx}\")\n                else:\n                    current_preds.append((start_idx, end_idx))\n                start_idx = None\n        if test:\n            all_predictions.append(\"; \".join(current_preds))\n        else:\n            all_predictions.append(current_preds)\n            \n    return all_predictions\n\n\ndef calculate_char_cv(predictions, offset_mapping, sequence_ids, labels):\n    all_labels = []\n    all_preds = []\n    for preds, offsets, seq_ids, labels in zip(predictions, offset_mapping, sequence_ids, labels):\n\n        num_chars = max(list(chain(*offsets)))\n        char_labels = np.zeros(num_chars)\n\n        for o, s_id, label in zip(offsets, seq_ids, labels):\n            if s_id is None or s_id == 0:\n                continue\n            if int(label) == 1:\n                char_labels[o[0]:o[1]] = 1\n\n        char_preds = np.zeros(num_chars)\n\n        for start_idx, end_idx in preds:\n            char_preds[start_idx:end_idx] = 1\n\n        all_labels.extend(char_labels)\n        all_preds.extend(char_preds)\n\n    results = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\", labels=np.unique(all_preds))\n    accuracy = accuracy_score(all_labels, all_preds)\n    \n\n    return {\n        \"Accuracy\": accuracy,\n        \"precision\": results[0],\n        \"recall\": results[1],\n        \"f1\": results[2]\n    }","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:27.571497Z","iopub.execute_input":"2022-03-17T12:14:27.572260Z","iopub.status.idle":"2022-03-17T12:14:27.586061Z","shell.execute_reply.started":"2022-03-17T12:14:27.572218Z","shell.execute_reply":"2022-03-17T12:14:27.585229Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data, tokenizer, config):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        data = self.data.iloc[idx]\n        tokens = tokenize_and_add_labels(self.tokenizer, data, self.config)\n\n        input_ids = np.array(tokens[\"input_ids\"])\n        attention_mask = np.array(tokens[\"attention_mask\"])\n        token_type_ids = np.array(tokens[\"token_type_ids\"])\n\n        labels = np.array(tokens[\"labels\"])\n        offset_mapping = np.array(tokens['offset_mapping'])\n        sequence_ids = np.array(tokens['sequence_ids']).astype(\"float16\")\n        \n        return input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:27.590206Z","iopub.execute_input":"2022-03-17T12:14:27.590689Z","iopub.status.idle":"2022-03-17T12:14:27.599224Z","shell.execute_reply.started":"2022-03-17T12:14:27.590661Z","shell.execute_reply":"2022-03-17T12:14:27.598536Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Model\n- Lets use **BERT** base Architecture\n- Also Used 3 FC layers\n\n**Comments:** 3 layers improve accuracy 2% on public score","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass CustomModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(config['model_name'])  # BERT model\n        self.dropout = nn.Dropout(p=config['dropout'])\n        self.config = config\n        self.fc1 = nn.Linear(768, 512)\n        #self.fc2 = nn.Linear(512, 512)\n        self.fc2 = nn.Linear(512, 1)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        logits = F.relu(self.fc1(outputs[0]))\n        #logits = self.fc2(self.dropout(logits))\n        logits = self.fc2(self.dropout(logits)).squeeze(-1)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:27.600437Z","iopub.execute_input":"2022-03-17T12:14:27.601229Z","iopub.status.idle":"2022-03-17T12:14:27.610128Z","shell.execute_reply.started":"2022-03-17T12:14:27.601180Z","shell.execute_reply":"2022-03-17T12:14:27.609294Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameters\n","metadata":{}},{"cell_type":"code","source":"hyperparameters = {\n    \"max_length\": 416,\n    \"padding\": \"max_length\",\n    \"return_offsets_mapping\": True,\n    \"truncation\": \"only_second\",\n    \"model_name\": \"../input/huggingface-bert/bert-base-uncased\",\n    \"dropout\": 0.2,\n    \"lr\": 1e-5,\n    \"test_size\": 0.2,\n    \"seed\": 1268,\n    \"batch_size\": 8\n}","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:27.611462Z","iopub.execute_input":"2022-03-17T12:14:27.611791Z","iopub.status.idle":"2022-03-17T12:14:27.618798Z","shell.execute_reply.started":"2022-03-17T12:14:27.611757Z","shell.execute_reply":"2022-03-17T12:14:27.618128Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Datasets\nTrain and Test split: 20%\n\nTotal Data:\n- Train: 11440\n- Test: 2860","metadata":{}},{"cell_type":"code","source":"train_df = prepare_datasets()\n\nX_train, X_test = train_test_split(train_df, test_size=hyperparameters['test_size'],\n                                   random_state=hyperparameters['seed'])\n\n\nprint(\"Train size\", len(X_train))\nprint(\"Test Size\", len(X_test))","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:27.620322Z","iopub.execute_input":"2022-03-17T12:14:27.620693Z","iopub.status.idle":"2022-03-17T12:14:28.807345Z","shell.execute_reply.started":"2022-03-17T12:14:27.620658Z","shell.execute_reply":"2022-03-17T12:14:28.806457Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Train size 11440\nTest Size 2860\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(hyperparameters['model_name'])\n\ntraining_data = CustomDataset(X_train, tokenizer, hyperparameters)\ntrain_dataloader = DataLoader(training_data, batch_size=hyperparameters['batch_size'], shuffle=True)\n\ntest_data = CustomDataset(X_test, tokenizer, hyperparameters)\ntest_dataloader = DataLoader(test_data, batch_size=hyperparameters['batch_size'], shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:31.468518Z","iopub.execute_input":"2022-03-17T12:14:31.468777Z","iopub.status.idle":"2022-03-17T12:14:31.541974Z","shell.execute_reply.started":"2022-03-17T12:14:31.468748Z","shell.execute_reply":"2022-03-17T12:14:31.541249Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Train\nLets train the model\nwith BCEWithLogitsLoss and AdamW as optimizer\n\n**Notes:** on BCEWithLogitsLoss, the default value for reduction is `mean` (the sum of the output will be divided by the number of elements in the output). If we use this default value, it will produce negative loss. Because we have some negative labels. To fix this negative loss issue, we can use `none` as parameter. To calculate the mean, first, we have to filter out the negative values. [DOC](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)","metadata":{}},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = CustomModel(hyperparameters).to(DEVICE)\n\ncriterion = torch.nn.BCEWithLogitsLoss(reduction = \"none\")\noptimizer = optim.AdamW(model.parameters(), lr=hyperparameters['lr'])","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:34.236910Z","iopub.execute_input":"2022-03-17T12:14:34.237487Z","iopub.status.idle":"2022-03-17T12:14:45.145362Z","shell.execute_reply.started":"2022-03-17T12:14:34.237429Z","shell.execute_reply":"2022-03-17T12:14:45.144585Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at ../input/huggingface-bert/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model(model, dataloader, optimizer, criterion):\n        model.train()\n        train_loss = []\n\n        for batch in tqdm(dataloader):\n            optimizer.zero_grad()\n            input_ids = batch[0].to(DEVICE)\n            attention_mask = batch[1].to(DEVICE)\n            token_type_ids = batch[2].to(DEVICE)\n            labels = batch[3].to(DEVICE)\n\n            logits = model(input_ids, attention_mask, token_type_ids)\n            loss = criterion(logits, labels)\n            # since, we have\n            loss = torch.masked_select(loss, labels > -1.0).mean()\n            train_loss.append(loss.item() * input_ids.size(0))\n            loss.backward()\n            # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n            # it's also improve f1 accuracy slightly\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n        return sum(train_loss)/len(train_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:45.146843Z","iopub.execute_input":"2022-03-17T12:14:45.147088Z","iopub.status.idle":"2022-03-17T12:14:45.156244Z","shell.execute_reply.started":"2022-03-17T12:14:45.147055Z","shell.execute_reply":"2022-03-17T12:14:45.155451Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, dataloader, criterion):\n        model.eval()\n        valid_loss = []\n        preds = []\n        offsets = []\n        seq_ids = []\n        valid_labels = []\n\n        for batch in tqdm(dataloader):\n            input_ids = batch[0].to(DEVICE)\n            attention_mask = batch[1].to(DEVICE)\n            token_type_ids = batch[2].to(DEVICE)\n            labels = batch[3].to(DEVICE)\n            offset_mapping = batch[4]\n            sequence_ids = batch[5]\n\n            logits = model(input_ids, attention_mask, token_type_ids)\n            loss = criterion(logits, labels)\n            loss = torch.masked_select(loss, labels > -1.0).mean()\n            valid_loss.append(loss.item() * input_ids.size(0))\n\n            preds.append(logits.detach().cpu().numpy())\n            offsets.append(offset_mapping.numpy())\n            seq_ids.append(sequence_ids.numpy())\n            valid_labels.append(labels.detach().cpu().numpy())\n\n        preds = np.concatenate(preds, axis=0)\n        offsets = np.concatenate(offsets, axis=0)\n        seq_ids = np.concatenate(seq_ids, axis=0)\n        valid_labels = np.concatenate(valid_labels, axis=0)\n        location_preds = get_location_predictions(preds, offsets, seq_ids, test=False)\n        score = calculate_char_cv(location_preds, offsets, seq_ids, valid_labels)\n\n        return sum(valid_loss)/len(valid_loss), score","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:14:45.157556Z","iopub.execute_input":"2022-03-17T12:14:45.157962Z","iopub.status.idle":"2022-03-17T12:14:45.171122Z","shell.execute_reply.started":"2022-03-17T12:14:45.157924Z","shell.execute_reply":"2022-03-17T12:14:45.169234Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import time\n\ntrain_loss_data, valid_loss_data = [], []\nscore_data_list = []\nvalid_loss_min = np.Inf\nsince = time.time()\nepochs = 6","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:15:31.620664Z","iopub.execute_input":"2022-03-17T12:15:31.621140Z","iopub.status.idle":"2022-03-17T12:15:31.625245Z","shell.execute_reply.started":"2022-03-17T12:15:31.621101Z","shell.execute_reply":"2022-03-17T12:15:31.624586Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"best_loss = np.inf\n\nfor i in range(epochs):\n    print(\"Epoch: {}/{}\".format(i + 1, epochs))\n    # first train model\n    train_loss = train_model(model, train_dataloader, optimizer, criterion)\n    train_loss_data.append(train_loss)\n    print(f\"Train loss: {train_loss}\")\n    # evaluate model\n    valid_loss, score = eval_model(model, test_dataloader, criterion)\n    valid_loss_data.append(valid_loss)\n    score_data_list.append(score)\n    print(f\"Valid loss: {valid_loss}\")\n    print(f\"Valid score: {score}\")\n    \n    if valid_loss < best_loss:\n        best_loss = valid_loss\n        torch.save(model.state_dict(), \"nbme_bert_v2.pth\")\n\n    \ntime_elapsed = time.time() - since\nprint('Training completed in {:.0f}m {:.0f}s'.format(\n    time_elapsed // 60, time_elapsed % 60))","metadata":{"execution":{"iopub.status.busy":"2022-03-17T12:15:49.699608Z","iopub.execute_input":"2022-03-17T12:15:49.700163Z","iopub.status.idle":"2022-03-17T13:18:35.518331Z","shell.execute_reply.started":"2022-03-17T12:15:49.700122Z","shell.execute_reply":"2022-03-17T13:18:35.517441Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch: 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb943de6f1ee46a6b0e38f798d16bb8e"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.35295103162528574\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0737d54e6d2e4bf4a2dd864b54ee333e"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.16230798886371106\nValid score: {'Accuracy': 0.9919332497687152, 'precision': 0.7324110204564266, 'recall': 0.7162142630011852, 'f1': 0.7242220955554579}\nEpoch: 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38c6779a7bdc480d8688fd50ef5d6aba"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.14201968794996947\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"127677fae4774481b902a2e9ea5fa059"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.12897268847737386\nValid score: {'Accuracy': 0.9930670152895891, 'precision': 0.7405361537253259, 'recall': 0.8177087850143092, 'f1': 0.7772114684507699}\nEpoch: 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25dd964bcbe44ccdabe971f76f4355ad"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.09999713796705431\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e608558f3e264bcda84eb7747c4868d9"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.12724611056010968\nValid score: {'Accuracy': 0.9932414407543388, 'precision': 0.7453628716233868, 'recall': 0.8247622351342757, 'f1': 0.7830549875807934}\nEpoch: 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b182e44fe8e1445d9ebdecb689f29563"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.07454096774082057\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2acd6884e0544d89884e041f9c7426e1"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.12598719054775992\nValid score: {'Accuracy': 0.9930490597270413, 'precision': 0.7192537670413777, 'recall': 0.8693088197034082, 'f1': 0.7871942201222465}\nEpoch: 5/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d305016ddc544c983658dae74dfa821"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.05900900677642416\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2923f0161cd4800869ce844fad8ee75"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.13031108788355703\nValid score: {'Accuracy': 0.993469305393338, 'precision': 0.7432442642355253, 'recall': 0.853120573526436, 'f1': 0.7944010767160161}\nEpoch: 6/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"127b59d170684c9dbac9ea0d2a3f61a2"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.046798826838965524\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92baf60ba9f84b16ba190de7c18aaa69"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.13794055755054735\nValid score: {'Accuracy': 0.9938438071264772, 'precision': 0.7748319133298854, 'recall': 0.8228543346919898, 'f1': 0.7981214075424086}\nTraining completed in 63m 4s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Experimets:\n- exp 1\nParams: Base bert with 1FC, epoch 5, lr 1e-5\n\n{'Accuracy': 0.9922235313632376, 'precision': 0.699022058288238, 'recall': 0.8327118203104674, 'f1': 0.7600327168148598}\n\n- exp 2:\nParams: Base bert with 2FC, epoch 2, lr 1e-5\n\n{'Accuracy': 0.9931995444417273, 'precision': 0.755762387079113, 'recall': 0.7980805365247304, 'f1': 0.7763452047860748}\n\n- exp 3:\nparams: 2FC, epoch 2, lr 1e-5 with gradient clip\n{'Accuracy': 0.9932764968526464, 'precision': 0.7633003963601853, 'recall': 0.7905067499205042, 'f1': 0.7766653886025079}\n\n- exp 4: 3FC, epoch 2, 1e-5 with gradient clip\n\n{'Accuracy': 0.9933637095850213, 'precision': 0.7576469952442715, 'recall': 0.8105397045645073, 'f1': 0.7832013519364255}\n","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nplt.plot(train_loss_data, label=\"Training loss\")\nplt.plot(valid_loss_data, label=\"validation loss\")\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T13:21:19.790422Z","iopub.execute_input":"2022-03-17T13:21:19.790688Z","iopub.status.idle":"2022-03-17T13:21:20.040769Z","shell.execute_reply.started":"2022-03-17T13:21:19.790657Z","shell.execute_reply":"2022-03-17T13:21:20.040041Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x7f628de87f10>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"import pandas as pd\n\nscore_df = pd.DataFrame.from_dict(score_data_list)\nscore_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T13:21:28.412006Z","iopub.execute_input":"2022-03-17T13:21:28.412271Z","iopub.status.idle":"2022-03-17T13:21:28.427894Z","shell.execute_reply.started":"2022-03-17T13:21:28.412239Z","shell.execute_reply":"2022-03-17T13:21:28.427059Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   Accuracy  precision    recall        f1\n0  0.991933   0.732411  0.716214  0.724222\n1  0.993067   0.740536  0.817709  0.777211\n2  0.993241   0.745363  0.824762  0.783055\n3  0.993049   0.719254  0.869309  0.787194\n4  0.993469   0.743244  0.853121  0.794401","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.991933</td>\n      <td>0.732411</td>\n      <td>0.716214</td>\n      <td>0.724222</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.993067</td>\n      <td>0.740536</td>\n      <td>0.817709</td>\n      <td>0.777211</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.993241</td>\n      <td>0.745363</td>\n      <td>0.824762</td>\n      <td>0.783055</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.993049</td>\n      <td>0.719254</td>\n      <td>0.869309</td>\n      <td>0.787194</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.993469</td>\n      <td>0.743244</td>\n      <td>0.853121</td>\n      <td>0.794401</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Prepare For Testing","metadata":{}},{"cell_type":"markdown","source":"Load best model","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"nbme_bert_v2.pth\", map_location = DEVICE))","metadata":{"execution":{"iopub.status.busy":"2022-03-17T13:21:34.483372Z","iopub.execute_input":"2022-03-17T13:21:34.485457Z","iopub.status.idle":"2022-03-17T13:21:34.737856Z","shell.execute_reply.started":"2022-03-17T13:21:34.485418Z","shell.execute_reply":"2022-03-17T13:21:34.737065Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"def create_test_df():\n    feats = pd.read_csv(f\"{BASE_URL}/features.csv\")\n    notes = pd.read_csv(f\"{BASE_URL}/patient_notes.csv\")\n    test = pd.read_csv(f\"{BASE_URL}/test.csv\")\n\n    merged = test.merge(notes, how = \"left\")\n    merged = merged.merge(feats, how = \"left\")\n\n    def process_feature_text(text):\n        return text.replace(\"-OR-\", \";-\").replace(\"-\", \" \")\n    \n    merged[\"feature_text\"] = [process_feature_text(x) for x in merged[\"feature_text\"]]\n    \n    return merged\n\n\nclass SubmissionDataset(Dataset):\n    def __init__(self, data, tokenizer, config):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        example = self.data.loc[idx]\n        tokenized = self.tokenizer(\n            example[\"feature_text\"],\n            example[\"pn_history\"],\n            truncation = self.config['truncation'],\n            max_length = self.config['max_length'],\n            padding = self.config['padding'],\n            return_offsets_mapping = self.config['return_offsets_mapping']\n        )\n        tokenized[\"sequence_ids\"] = tokenized.sequence_ids()\n\n        input_ids = np.array(tokenized[\"input_ids\"])\n        attention_mask = np.array(tokenized[\"attention_mask\"])\n        token_type_ids = np.array(tokenized[\"token_type_ids\"])\n        offset_mapping = np.array(tokenized[\"offset_mapping\"])\n        sequence_ids = np.array(tokenized[\"sequence_ids\"]).astype(\"float16\")\n\n        return input_ids, attention_mask, token_type_ids, offset_mapping, sequence_ids\n\n\ntest_df = create_test_df()\n\nsubmission_data = SubmissionDataset(test_df, tokenizer, hyperparameters)\nsubmission_dataloader = DataLoader(submission_data, batch_size=hyperparameters['batch_size'], shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T13:21:40.122113Z","iopub.execute_input":"2022-03-17T13:21:40.122382Z","iopub.status.idle":"2022-03-17T13:21:40.450421Z","shell.execute_reply.started":"2022-03-17T13:21:40.122351Z","shell.execute_reply":"2022-03-17T13:21:40.449676Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.eval()\npreds = []\noffsets = []\nseq_ids = []\n\nfor batch in tqdm(submission_dataloader):\n    input_ids = batch[0].to(DEVICE)\n    attention_mask = batch[1].to(DEVICE)\n    token_type_ids = batch[2].to(DEVICE)\n    offset_mapping = batch[3]\n    sequence_ids = batch[4]\n\n    logits = model(input_ids, attention_mask, token_type_ids)\n    \n    preds.append(logits.detach().cpu().numpy())\n    offsets.append(offset_mapping.numpy())\n    seq_ids.append(sequence_ids.numpy())\n\npreds = np.concatenate(preds, axis=0)\noffsets = np.concatenate(offsets, axis=0)\nseq_ids = np.concatenate(seq_ids, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T13:21:41.162908Z","iopub.execute_input":"2022-03-17T13:21:41.163421Z","iopub.status.idle":"2022-03-17T13:21:41.302328Z","shell.execute_reply.started":"2022-03-17T13:21:41.163385Z","shell.execute_reply":"2022-03-17T13:21:41.301677Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e6fd3542e5b4dc59f0a5f3c4feda27f"}},"metadata":{}}]},{"cell_type":"code","source":"location_preds = get_location_predictions(preds, offsets, seq_ids, test=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T13:21:41.854918Z","iopub.execute_input":"2022-03-17T13:21:41.855219Z","iopub.status.idle":"2022-03-17T13:21:41.872660Z","shell.execute_reply.started":"2022-03-17T13:21:41.855180Z","shell.execute_reply":"2022-03-17T13:21:41.871841Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"len(location_preds), len(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T13:21:42.554336Z","iopub.execute_input":"2022-03-17T13:21:42.554541Z","iopub.status.idle":"2022-03-17T13:21:42.560012Z","shell.execute_reply.started":"2022-03-17T13:21:42.554516Z","shell.execute_reply":"2022-03-17T13:21:42.559122Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(5, 5)"},"metadata":{}}]},{"cell_type":"code","source":"test_df[\"location\"] = location_preds","metadata":{"execution":{"iopub.status.busy":"2022-03-17T13:21:42.956935Z","iopub.execute_input":"2022-03-17T13:21:42.957127Z","iopub.status.idle":"2022-03-17T13:21:42.962766Z","shell.execute_reply.started":"2022-03-17T13:21:42.957104Z","shell.execute_reply":"2022-03-17T13:21:42.962054Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test_df[[\"id\", \"location\"]].to_csv(\"submission.csv\", index = False)\npd.read_csv(\"submission.csv\").head()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T13:21:43.741457Z","iopub.execute_input":"2022-03-17T13:21:43.741959Z","iopub.status.idle":"2022-03-17T13:21:43.757682Z","shell.execute_reply.started":"2022-03-17T13:21:43.741920Z","shell.execute_reply":"2022-03-17T13:21:43.756907Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"          id           location\n0  00016_000            696 724\n1  00016_001            668 693\n2  00016_002            203 217\n3  00016_003     70 91; 176 183\n4  00016_004  222 258; 0 0; 0 0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00016_000</td>\n      <td>696 724</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00016_001</td>\n      <td>668 693</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00016_002</td>\n      <td>203 217</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00016_003</td>\n      <td>70 91; 176 183</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00016_004</td>\n      <td>222 258; 0 0; 0 0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Special Credits\n- [tomohiroh](https://www.kaggle.com/tomohiroh/nbme-bert-for-beginners)\n- [gazu468](https://www.kaggle.com/gazu468/nbme-details-eda)\n","metadata":{}}]}