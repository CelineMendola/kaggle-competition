{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NBME - Score Clinical Patient Notes \n- **Framework:** Pytorch\n- **Model Architecture:**\n    - BERT\n    - Linear(768, 512)\n    - Linear(512, 512)\n    - Linear(512, 1)\n- **LR:** 1e-5\n- **Batch Size:** 8\n- **Epoch:** 3\n- **Dropout:** 0.2\n- **Criterion:** BCEWithLogitsLoss\n- **Optimizer:** AdamW\n\n# Tokenizer params\n- **Max Lenght:** 416\n- **Padding:** max_lenght\n- **Truncation:** only_scond\n","metadata":{}},{"cell_type":"code","source":"from ast import literal_eval\nfrom itertools import chain\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.model_selection import train_test_split\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom tqdm.notebook import tqdm\nfrom transformers import AutoModel, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:44.842194Z","iopub.execute_input":"2022-03-16T15:24:44.842449Z","iopub.status.idle":"2022-03-16T15:24:44.849804Z","shell.execute_reply.started":"2022-03-16T15:24:44.842421Z","shell.execute_reply":"2022-03-16T15:24:44.849000Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":"# Helper Functions\n### 1. Datasets Helper Function\nneed to merge `features.csv`, `patient_notes.csv` with `train.csv`","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:44.851692Z","iopub.execute_input":"2022-03-16T15:24:44.852467Z","iopub.status.idle":"2022-03-16T15:24:44.860997Z","shell.execute_reply.started":"2022-03-16T15:24:44.852405Z","shell.execute_reply":"2022-03-16T15:24:44.860215Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"BASE_URL = \"../input/nbme-score-clinical-patient-notes\"\n\n\ndef process_feature_text(text):\n    return text.replace(\"-OR-\", \";-\").replace(\"-\", \" \")\n\n\ndef prepare_datasets():\n    features = pd.read_csv(f\"{BASE_URL}/features.csv\")\n    notes = pd.read_csv(f\"{BASE_URL}/patient_notes.csv\")\n    df = pd.read_csv(f\"{BASE_URL}/train.csv\")\n    df[\"annotation_list\"] = [literal_eval(x) for x in df[\"annotation\"]]\n    df[\"location_list\"] = [literal_eval(x) for x in df[\"location\"]]\n\n    merged = df.merge(notes, how=\"left\")\n    merged = merged.merge(features, how=\"left\")\n\n    merged[\"feature_text\"] = [process_feature_text(x) for x in merged[\"feature_text\"]]\n    merged[\"feature_text\"] = merged[\"feature_text\"].apply(lambda x: x.lower())\n    merged[\"pn_history\"] = merged[\"pn_history\"].apply(lambda x: x.lower())\n\n    return merged","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:44.862306Z","iopub.execute_input":"2022-03-16T15:24:44.862666Z","iopub.status.idle":"2022-03-16T15:24:44.873942Z","shell.execute_reply.started":"2022-03-16T15:24:44.862611Z","shell.execute_reply":"2022-03-16T15:24:44.873237Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"dg = prepare_datasets()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:44.875554Z","iopub.execute_input":"2022-03-16T15:24:44.875827Z","iopub.status.idle":"2022-03-16T15:24:45.440357Z","shell.execute_reply.started":"2022-03-16T15:24:44.875794Z","shell.execute_reply":"2022-03-16T15:24:45.439650Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"dg.loc[15:35,:]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dg.loc[15:35,:]\n\ndg.location_list[0][0]","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.473627Z","iopub.execute_input":"2022-03-16T15:24:45.473909Z","iopub.status.idle":"2022-03-16T15:24:45.481722Z","shell.execute_reply.started":"2022-03-16T15:24:45.473873Z","shell.execute_reply":"2022-03-16T15:24:45.480929Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"'696 724'"},"metadata":{}}]},{"cell_type":"code","source":"dg.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.483446Z","iopub.execute_input":"2022-03-16T15:24:45.483868Z","iopub.status.idle":"2022-03-16T15:24:45.491862Z","shell.execute_reply.started":"2022-03-16T15:24:45.483832Z","shell.execute_reply":"2022-03-16T15:24:45.491063Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"(14300, 10)"},"metadata":{}}]},{"cell_type":"code","source":"features = pd.read_csv(f\"{BASE_URL}/features.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.493042Z","iopub.execute_input":"2022-03-16T15:24:45.493435Z","iopub.status.idle":"2022-03-16T15:24:45.500804Z","shell.execute_reply.started":"2022-03-16T15:24:45.493396Z","shell.execute_reply":"2022-03-16T15:24:45.500139Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.501910Z","iopub.execute_input":"2022-03-16T15:24:45.503298Z","iopub.status.idle":"2022-03-16T15:24:45.512582Z","shell.execute_reply.started":"2022-03-16T15:24:45.503269Z","shell.execute_reply":"2022-03-16T15:24:45.511796Z"},"trusted":true},"execution_count":126,"outputs":[{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"   feature_num  case_num  \\\n0            0         0   \n1            1         0   \n2            2         0   \n3            3         0   \n4            4         0   \n\n                                                      feature_text  \n0  Family-history-of-MI-OR-Family-history-of-myocardial-infarction  \n1                               Family-history-of-thyroid-disorder  \n2                                                   Chest-pressure  \n3                                            Intermittent-symptoms  \n4                                                      Lightheaded  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_num</th>\n      <th>case_num</th>\n      <th>feature_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Family-history-of-MI-OR-Family-history-of-myocardial-infarction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>Family-history-of-thyroid-disorder</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>Chest-pressure</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>Intermittent-symptoms</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>Lightheaded</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"features.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.513790Z","iopub.execute_input":"2022-03-16T15:24:45.514366Z","iopub.status.idle":"2022-03-16T15:24:45.519463Z","shell.execute_reply.started":"2022-03-16T15:24:45.514329Z","shell.execute_reply":"2022-03-16T15:24:45.518763Z"},"trusted":true},"execution_count":127,"outputs":[{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"(143, 3)"},"metadata":{}}]},{"cell_type":"code","source":"features.groupby('case_num').size()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.520722Z","iopub.execute_input":"2022-03-16T15:24:45.521305Z","iopub.status.idle":"2022-03-16T15:24:45.530934Z","shell.execute_reply.started":"2022-03-16T15:24:45.521270Z","shell.execute_reply":"2022-03-16T15:24:45.530121Z"},"trusted":true},"execution_count":128,"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"case_num\n0    13\n1    13\n2    17\n3    16\n4    10\n5    18\n6    12\n7     9\n8    18\n9    17\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.532253Z","iopub.execute_input":"2022-03-16T15:24:45.533229Z","iopub.status.idle":"2022-03-16T15:24:45.536955Z","shell.execute_reply.started":"2022-03-16T15:24:45.533192Z","shell.execute_reply":"2022-03-16T15:24:45.536054Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"features[features['case_num']==0]","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.541140Z","iopub.execute_input":"2022-03-16T15:24:45.541777Z","iopub.status.idle":"2022-03-16T15:24:45.552952Z","shell.execute_reply.started":"2022-03-16T15:24:45.541736Z","shell.execute_reply":"2022-03-16T15:24:45.552300Z"},"trusted":true},"execution_count":130,"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"    feature_num  case_num  \\\n0             0         0   \n1             1         0   \n2             2         0   \n3             3         0   \n4             4         0   \n5             5         0   \n6             6         0   \n7             7         0   \n8             8         0   \n9             9         0   \n10           10         0   \n11           11         0   \n12           12         0   \n\n                                                        feature_text  \n0    Family-history-of-MI-OR-Family-history-of-myocardial-infarction  \n1                                 Family-history-of-thyroid-disorder  \n2                                                     Chest-pressure  \n3                                              Intermittent-symptoms  \n4                                                        Lightheaded  \n5   No-hair-changes-OR-no-nail-changes-OR-no-temperature-intolerance  \n6                                                       Adderall-use  \n7                                                Shortness-of-breath  \n8                                                       Caffeine-use  \n9                                     heart-pounding-OR-heart-racing  \n10                                               Few-months-duration  \n11                                                           17-year  \n12                                                              Male  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_num</th>\n      <th>case_num</th>\n      <th>feature_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Family-history-of-MI-OR-Family-history-of-myocardial-infarction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>Family-history-of-thyroid-disorder</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>Chest-pressure</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>Intermittent-symptoms</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>Lightheaded</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0</td>\n      <td>No-hair-changes-OR-no-nail-changes-OR-no-temperature-intolerance</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0</td>\n      <td>Adderall-use</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>0</td>\n      <td>Shortness-of-breath</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0</td>\n      <td>Caffeine-use</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0</td>\n      <td>heart-pounding-OR-heart-racing</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>0</td>\n      <td>Few-months-duration</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>0</td>\n      <td>17-year</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0</td>\n      <td>Male</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"features[features['case_num']==6]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features[features['case_num']==5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_notes = pd.read_csv(f\"{BASE_URL}/patient_notes.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.580628Z","iopub.execute_input":"2022-03-16T15:24:45.581142Z","iopub.status.idle":"2022-03-16T15:24:45.878032Z","shell.execute_reply.started":"2022-03-16T15:24:45.581104Z","shell.execute_reply":"2022-03-16T15:24:45.876841Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"patient_notes.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Tokenizer Helper Function","metadata":{}},{"cell_type":"code","source":"hyperparameters = {\n    \"max_length\": 416,\n    \"padding\": \"max_length\",\n    \"return_offsets_mapping\": True,\n    \"truncation\": \"only_second\",\n    \"model_name\": \"../input/huggingface-bert/bert-base-uncased\",\n    \"dropout\": 0.2,\n    \"lr\": 1e-5,\n    \"test_size\": 0.2,\n    \"seed\": 1268,\n    \"batch_size\": 8\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dg.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loc_list_to_ints(loc_list):\n    to_return = []\n    for loc_str in loc_list:\n        loc_strs = loc_str.split(\";\")\n        for loc in loc_strs:\n            start, end = loc.split()\n            to_return.append((int(start), int(end)))\n    return to_return\n\n\ndef tokenize_and_add_labels(tokenizer, data, config):\n    out = tokenizer(\n        data[\"feature_text\"],\n        data[\"pn_history\"],\n        truncation=config['truncation'],\n        max_length=config['max_length'],\n        padding=config['padding'],\n        return_offsets_mapping=config['return_offsets_mapping']\n    )\n    labels = [0.0] * len(out[\"input_ids\"])\n    out[\"location_int\"] = loc_list_to_ints(data[\"location_list\"])\n    out[\"sequence_ids\"] = out.sequence_ids()\n\n    for idx, (seq_id, offsets) in enumerate(zip(out[\"sequence_ids\"], out[\"offset_mapping\"])):\n        if not seq_id or seq_id == 0:\n            labels[idx] = -1\n            continue\n\n        token_start, token_end = offsets\n        for feature_start, feature_end in out[\"location_int\"]:\n            if token_start >= feature_start and token_end <= feature_end:\n                labels[idx] = 1.0\n                break\n\n    out[\"labels\"] = labels\n\n    return out\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.947298Z","iopub.execute_input":"2022-03-16T15:24:45.947825Z","iopub.status.idle":"2022-03-16T15:24:45.963340Z","shell.execute_reply.started":"2022-03-16T15:24:45.947775Z","shell.execute_reply":"2022-03-16T15:24:45.962022Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"markdown","source":"### 3. Predection and Score Helper Function","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ndef get_location_predictions(preds, offset_mapping, sequence_ids, test=False):\n    all_predictions = []\n    for pred, offsets, seq_ids in zip(preds, offset_mapping, sequence_ids):\n        pred = 1 / (1 + np.exp(-pred))\n        start_idx = None\n        end_idx = None\n        current_preds = []\n        for pred, offset, seq_id in zip(pred, offsets, seq_ids):\n            if seq_id is None or seq_id == 0:\n                continue\n\n            if pred > 0.5:\n                if start_idx is None:\n                    start_idx = offset[0]\n                end_idx = offset[1]\n            elif start_idx is not None:\n                if test:\n                    current_preds.append(f\"{start_idx} {end_idx}\")\n                else:\n                    current_preds.append((start_idx, end_idx))\n                start_idx = None\n        if test:\n            all_predictions.append(\"; \".join(current_preds))\n        else:\n            all_predictions.append(current_preds)\n            \n    return all_predictions\n\n\ndef calculate_char_cv(predictions, offset_mapping, sequence_ids, labels):\n    all_labels = []\n    all_preds = []\n    for preds, offsets, seq_ids, labels in zip(predictions, offset_mapping, sequence_ids, labels):\n\n        num_chars = max(list(chain(*offsets)))\n        char_labels = np.zeros(num_chars)\n\n        for o, s_id, label in zip(offsets, seq_ids, labels):\n            if s_id is None or s_id == 0:\n                continue\n            if int(label) == 1:\n                char_labels[o[0]:o[1]] = 1\n\n        char_preds = np.zeros(num_chars)\n\n        for start_idx, end_idx in preds:\n            char_preds[start_idx:end_idx] = 1\n\n        all_labels.extend(char_labels)\n        all_preds.extend(char_preds)\n\n    results = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\", labels=np.unique(all_preds))\n    accuracy = accuracy_score(all_labels, all_preds)\n    \n\n    return {\n        \"Accuracy\": accuracy,\n        \"precision\": results[0],\n        \"recall\": results[1],\n        \"f1\": results[2]\n    }","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.965863Z","iopub.execute_input":"2022-03-16T15:24:45.966579Z","iopub.status.idle":"2022-03-16T15:24:45.987291Z","shell.execute_reply.started":"2022-03-16T15:24:45.966447Z","shell.execute_reply":"2022-03-16T15:24:45.986554Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data, tokenizer, config):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        data = self.data.iloc[idx]\n        tokens = tokenize_and_add_labels(self.tokenizer, data, self.config)\n\n        input_ids = np.array(tokens[\"input_ids\"])\n        attention_mask = np.array(tokens[\"attention_mask\"])\n        token_type_ids = np.array(tokens[\"token_type_ids\"])\n\n        labels = np.array(tokens[\"labels\"])\n        offset_mapping = np.array(tokens['offset_mapping'])\n        sequence_ids = np.array(tokens['sequence_ids']).astype(\"float16\")\n        \n        return input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:45.988941Z","iopub.execute_input":"2022-03-16T15:24:45.989396Z","iopub.status.idle":"2022-03-16T15:24:46.000282Z","shell.execute_reply.started":"2022-03-16T15:24:45.989358Z","shell.execute_reply":"2022-03-16T15:24:45.999645Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"# Model\n- Lets use **BERT** base Architecture\n- Also Used 3 FC layers\n\n**Comments:** 3 layers improve accuracy 2% on public score","metadata":{}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(config['model_name'])  # BERT model\n        self.dropout = nn.Dropout(p=config['dropout'])\n        self.config = config\n        self.fc1 = nn.Linear(768, 416)\n        self.fc2 = nn.Linear(416,416)\n        self.fc3 = nn.Linear(416, 1)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        logits = self.fc1(outputs[0])\n        logits = self.fc2(self.dropout(logits))\n        logits = self.fc3(self.dropout(logits)).squeeze(-1)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:46.001618Z","iopub.execute_input":"2022-03-16T15:24:46.002010Z","iopub.status.idle":"2022-03-16T15:24:46.014613Z","shell.execute_reply.started":"2022-03-16T15:24:46.001974Z","shell.execute_reply":"2022-03-16T15:24:46.013817Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameters\n","metadata":{}},{"cell_type":"code","source":"hyperparameters = {\n    \"max_length\": 416,\n    \"padding\": \"max_length\",\n    \"return_offsets_mapping\": True,\n    \"truncation\": \"only_second\",\n    \"model_name\": \"../input/huggingface-bert/bert-base-uncased\",\n    \"dropout\": 0.2,\n    \"lr\": 1e-5,\n    \"test_size\": 0.2,\n    \"seed\": 1268,\n    \"batch_size\": 8\n}","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:46.016016Z","iopub.execute_input":"2022-03-16T15:24:46.016479Z","iopub.status.idle":"2022-03-16T15:24:46.022682Z","shell.execute_reply.started":"2022-03-16T15:24:46.016440Z","shell.execute_reply":"2022-03-16T15:24:46.021862Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Datasets\nTrain and Test split: 20%\n\nTotal Data:\n- Train: 11440\n- Test: 2860","metadata":{}},{"cell_type":"code","source":"train_df = prepare_datasets()\n\nX_train, X_test = train_test_split(train_df, test_size=hyperparameters['test_size'],\n                                   random_state=hyperparameters['seed'])\n\n\nprint(\"Train size\", len(X_train))\nprint(\"Test Size\", len(X_test))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:46.024091Z","iopub.execute_input":"2022-03-16T15:24:46.024556Z","iopub.status.idle":"2022-03-16T15:24:46.708017Z","shell.execute_reply.started":"2022-03-16T15:24:46.024518Z","shell.execute_reply":"2022-03-16T15:24:46.707302Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"Train size 11440\nTest Size 2860\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(hyperparameters['model_name'])\n\ntraining_data = CustomDataset(X_train, tokenizer, hyperparameters)\ntrain_dataloader = DataLoader(training_data, batch_size=hyperparameters['batch_size'], shuffle=True)\n\ntest_data = CustomDataset(X_test, tokenizer, hyperparameters)\ntest_dataloader = DataLoader(test_data, batch_size=hyperparameters['batch_size'], shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:46.709333Z","iopub.execute_input":"2022-03-16T15:24:46.709578Z","iopub.status.idle":"2022-03-16T15:24:46.751204Z","shell.execute_reply.started":"2022-03-16T15:24:46.709544Z","shell.execute_reply":"2022-03-16T15:24:46.750529Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"markdown","source":"# Train\nLets train the model\nwith BCEWithLogitsLoss and AdamW as optimizer\n\n**Notes:** on BCEWithLogitsLoss, the default value for reduction is `mean` (the sum of the output will be divided by the number of elements in the output). If we use this default value, it will produce negative loss. Because we have some negative labels. To fix this negative loss issue, we can use `none` as parameter. To calculate the mean, first, we have to filter out the negative values. [DOC](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)","metadata":{}},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = CustomModel(hyperparameters).to(DEVICE)\ncriterion = torch.nn.BCEWithLogitsLoss(reduction = \"none\")\noptimizer = optim.AdamW(model.parameters(), lr=hyperparameters['lr'])","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:46.752796Z","iopub.execute_input":"2022-03-16T15:24:46.753079Z","iopub.status.idle":"2022-03-16T15:24:48.115900Z","shell.execute_reply.started":"2022-03-16T15:24:46.753040Z","shell.execute_reply":"2022-03-16T15:24:48.115124Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at ../input/huggingface-bert/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model(model, dataloader, optimizer, criterion):\n        model.train()\n        train_loss = []\n\n        for batch in tqdm(dataloader):\n            optimizer.zero_grad()\n            input_ids = batch[0].to(DEVICE)\n            attention_mask = batch[1].to(DEVICE)\n            token_type_ids = batch[2].to(DEVICE)\n            labels = batch[3].to(DEVICE)\n\n            logits = model(input_ids, attention_mask, token_type_ids)\n            loss = criterion(logits, labels)\n            # since, we have\n            loss = torch.masked_select(loss, labels > -1.0).mean()\n            train_loss.append(loss.item() * input_ids.size(0))\n            loss.backward()\n            # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n            # it's also improve f1 accuracy slightly\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n        return sum(train_loss)/len(train_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:48.117523Z","iopub.execute_input":"2022-03-16T15:24:48.117769Z","iopub.status.idle":"2022-03-16T15:24:48.125865Z","shell.execute_reply.started":"2022-03-16T15:24:48.117736Z","shell.execute_reply":"2022-03-16T15:24:48.124809Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, dataloader, criterion):\n        model.eval()\n        valid_loss = []\n        preds = []\n        offsets = []\n        seq_ids = []\n        valid_labels = []\n\n        for batch in tqdm(dataloader):\n            input_ids = batch[0].to(DEVICE)\n            attention_mask = batch[1].to(DEVICE)\n            token_type_ids = batch[2].to(DEVICE)\n            labels = batch[3].to(DEVICE)\n            offset_mapping = batch[4]\n            sequence_ids = batch[5]\n\n            logits = model(input_ids, attention_mask, token_type_ids)\n            loss = criterion(logits, labels)\n            loss = torch.masked_select(loss, labels > -1.0).mean()\n            valid_loss.append(loss.item() * input_ids.size(0))\n\n            preds.append(logits.detach().cpu().numpy())\n            offsets.append(offset_mapping.numpy())\n            seq_ids.append(sequence_ids.numpy())\n            valid_labels.append(labels.detach().cpu().numpy())\n\n        preds = np.concatenate(preds, axis=0)\n        offsets = np.concatenate(offsets, axis=0)\n        seq_ids = np.concatenate(seq_ids, axis=0)\n        valid_labels = np.concatenate(valid_labels, axis=0)\n        location_preds = get_location_predictions(preds, offsets, seq_ids, test=False)\n        score = calculate_char_cv(location_preds, offsets, seq_ids, valid_labels)\n\n        return sum(valid_loss)/len(valid_loss), score","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:24:48.127411Z","iopub.execute_input":"2022-03-16T15:24:48.127990Z","iopub.status.idle":"2022-03-16T15:24:48.140309Z","shell.execute_reply.started":"2022-03-16T15:24:48.127942Z","shell.execute_reply":"2022-03-16T15:24:48.139631Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"import time\n\ntrain_loss_data, valid_loss_data = [], []\nscore_data_list = []\nvalid_loss_min = np.Inf\nsince = time.time()\nepochs = 6","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:31:13.345551Z","iopub.execute_input":"2022-03-16T15:31:13.346222Z","iopub.status.idle":"2022-03-16T15:31:13.351481Z","shell.execute_reply.started":"2022-03-16T15:31:13.346186Z","shell.execute_reply":"2022-03-16T15:31:13.350666Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"best_loss = np.inf\n\nfor i in range(epochs):\n    print(\"Epoch: {}/{}\".format(i + 1, epochs))\n    # first train model\n    train_loss = train_model(model, train_dataloader, optimizer, criterion)\n    train_loss_data.append(train_loss)\n    print(f\"Train loss: {train_loss}\")\n    # evaluate model\n    valid_loss, score = eval_model(model, test_dataloader, criterion)\n    valid_loss_data.append(valid_loss)\n    score_data_list.append(score)\n    print(f\"Valid loss: {valid_loss}\")\n    print(f\"Valid score: {score}\")\n    \n    if valid_loss < best_loss:\n        best_loss = valid_loss\n        torch.save(model.state_dict(), \"nbme_bert_v2.pth\")\n\n    \ntime_elapsed = time.time() - since\nprint('Training completed in {:.0f}m {:.0f}s'.format(\n    time_elapsed // 60, time_elapsed % 60))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:31:31.527541Z","iopub.execute_input":"2022-03-16T15:31:31.528107Z","iopub.status.idle":"2022-03-16T16:34:24.727700Z","shell.execute_reply.started":"2022-03-16T15:31:31.528069Z","shell.execute_reply":"2022-03-16T16:34:24.726992Z"},"trusted":true},"execution_count":148,"outputs":[{"name":"stdout","text":"Epoch: 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf67b7ca477a4172902a7abe5b8404fa"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.3278561281273371\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c84a8d817c4368b79c938db4256aed"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.15729387789672522\nValid score: {'Accuracy': 0.9920726191351575, 'precision': 0.7896275443915115, 'recall': 0.6324689966178129, 'f1': 0.7023643280204172}\nEpoch: 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"009c6db7ea1e467399467bd5066cad50"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.13648602448120942\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83dc7c85f1d34530affff5ec1d24db05"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.1416691186126802\nValid score: {'Accuracy': 0.9916117596964313, 'precision': 0.6626896162037641, 'recall': 0.8814789119185963, 'f1': 0.7565844157455307}\nEpoch: 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b259b0a31e7d4a3c83394ad1c17e6ab6"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.09655808775687458\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb7e2007ea5a431bb6a6d72c868844f3"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.12041862947973316\nValid score: {'Accuracy': 0.9934787106880059, 'precision': 0.7590622906898862, 'recall': 0.8190096262249588, 'f1': 0.7878973275118886}\nEpoch: 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2925cabcd1247568421f62e0b7dc5a0"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.07343439092672038\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be563f7518444259bea1c68ecd75017e"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.11918049407265073\nValid score: {'Accuracy': 0.9933363487278056, 'precision': 0.7335922521016666, 'recall': 0.8627178909027838, 'f1': 0.7929325805380273}\nEpoch: 5/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"305cbbfb08b34714994e2773b613b2e3"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.05710731247096893\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"438fee8acca94cddb639b130acd36450"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.1362572661314578\nValid score: {'Accuracy': 0.9939968569215274, 'precision': 0.7843799297041486, 'recall': 0.8192987020495476, 'f1': 0.8014591522212482}\nEpoch: 6/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96d8e30f200e440e9e1a3d4bfb67c2bc"}},"metadata":{}},{"name":"stdout","text":"Train loss: 0.0450132778072324\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e86452f5aba4da3a1d5810d8cdbb6f2"}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.14813122544671808\nValid score: {'Accuracy': 0.9940947574887521, 'precision': 0.7844393342093736, 'recall': 0.8283178677767178, 'f1': 0.8057816959829024}\nTraining completed in 63m 11s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Experimets:\n- exp 1\nParams: Base bert with 1FC, epoch 5, lr 1e-5\n\n{'Accuracy': 0.9922235313632376, 'precision': 0.699022058288238, 'recall': 0.8327118203104674, 'f1': 0.7600327168148598}\n\n- exp 2:\nParams: Base bert with 2FC, epoch 2, lr 1e-5\n\n{'Accuracy': 0.9931995444417273, 'precision': 0.755762387079113, 'recall': 0.7980805365247304, 'f1': 0.7763452047860748}\n\n- exp 3:\nparams: 2FC, epoch 2, lr 1e-5 with gradient clip\n{'Accuracy': 0.9932764968526464, 'precision': 0.7633003963601853, 'recall': 0.7905067499205042, 'f1': 0.7766653886025079}\n\n- exp 4: 3FC, epoch 2, 1e-5 with gradient clip\n\n{'Accuracy': 0.9933637095850213, 'precision': 0.7576469952442715, 'recall': 0.8105397045645073, 'f1': 0.7832013519364255}\n","metadata":{}},{"cell_type":"code","source":"dg","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:26:24.281954Z","iopub.execute_input":"2022-03-16T17:26:24.282331Z","iopub.status.idle":"2022-03-16T17:26:24.296794Z","shell.execute_reply.started":"2022-03-16T17:26:24.282298Z","shell.execute_reply":"2022-03-16T17:26:24.295730Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/1056888925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'dg' is not defined"],"ename":"NameError","evalue":"name 'dg' is not defined","output_type":"error"}]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nplt.plot(train_loss_data, label=\"Training loss\")\nplt.plot(valid_loss_data, label=\"validation loss\")\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:58:01.236866Z","iopub.execute_input":"2022-03-16T16:58:01.237304Z","iopub.status.idle":"2022-03-16T16:58:01.320799Z","shell.execute_reply.started":"2022-03-16T16:58:01.237199Z","shell.execute_reply":"2022-03-16T16:58:01.319849Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/312346400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loss_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_loss_data' is not defined"],"ename":"NameError","evalue":"name 'train_loss_data' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\n\nscore_df = pd.DataFrame.from_dict(score_data_list)\nscore_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:51:22.937258Z","iopub.execute_input":"2022-02-14T17:51:22.937911Z","iopub.status.idle":"2022-02-14T17:51:22.949599Z","shell.execute_reply.started":"2022-02-14T17:51:22.937875Z","shell.execute_reply":"2022-02-14T17:51:22.948962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare For Testing","metadata":{}},{"cell_type":"markdown","source":"Load best model","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"nbme_bert_v2.pth\", map_location = DEVICE))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:51:33.339694Z","iopub.execute_input":"2022-02-14T17:51:33.339963Z","iopub.status.idle":"2022-02-14T17:51:33.565648Z","shell.execute_reply.started":"2022-02-14T17:51:33.339918Z","shell.execute_reply":"2022-02-14T17:51:33.564786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_test_df():\n    feats = pd.read_csv(f\"{BASE_URL}/features.csv\")\n    notes = pd.read_csv(f\"{BASE_URL}/patient_notes.csv\")\n    test = pd.read_csv(f\"{BASE_URL}/test.csv\")\n\n    merged = test.merge(notes, how = \"left\")\n    merged = merged.merge(feats, how = \"left\")\n\n    def process_feature_text(text):\n        return text.replace(\"-OR-\", \";-\").replace(\"-\", \" \")\n    \n    merged[\"feature_text\"] = [process_feature_text(x) for x in merged[\"feature_text\"]]\n    \n    return merged\n\n\nclass SubmissionDataset(Dataset):\n    def __init__(self, data, tokenizer, config):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        example = self.data.loc[idx]\n        tokenized = self.tokenizer(\n            example[\"feature_text\"],\n            example[\"pn_history\"],\n            truncation = self.config['truncation'],\n            max_length = self.config['max_length'],\n            padding = self.config['padding'],\n            return_offsets_mapping = self.config['return_offsets_mapping']\n        )\n        tokenized[\"sequence_ids\"] = tokenized.sequence_ids()\n\n        input_ids = np.array(tokenized[\"input_ids\"])\n        attention_mask = np.array(tokenized[\"attention_mask\"])\n        token_type_ids = np.array(tokenized[\"token_type_ids\"])\n        offset_mapping = np.array(tokenized[\"offset_mapping\"])\n        sequence_ids = np.array(tokenized[\"sequence_ids\"]).astype(\"float16\")\n\n        return input_ids, attention_mask, token_type_ids, offset_mapping, sequence_ids\n\n\ntest_df = create_test_df()\n\nsubmission_data = SubmissionDataset(test_df, tokenizer, hyperparameters)\nsubmission_dataloader = DataLoader(submission_data, batch_size=hyperparameters['batch_size'], shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:43:14.28865Z","iopub.execute_input":"2022-02-15T04:43:14.288938Z","iopub.status.idle":"2022-02-15T04:43:14.615585Z","shell.execute_reply.started":"2022-02-15T04:43:14.288889Z","shell.execute_reply":"2022-02-15T04:43:14.614876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\npreds = []\noffsets = []\nseq_ids = []\n\nfor batch in tqdm(submission_dataloader):\n    input_ids = batch[0].to(DEVICE)\n    attention_mask = batch[1].to(DEVICE)\n    token_type_ids = batch[2].to(DEVICE)\n    offset_mapping = batch[3]\n    sequence_ids = batch[4]\n\n    logits = model(input_ids, attention_mask, token_type_ids)\n    \n    preds.append(logits.detach().cpu().numpy())\n    offsets.append(offset_mapping.numpy())\n    seq_ids.append(sequence_ids.numpy())\n\npreds = np.concatenate(preds, axis=0)\noffsets = np.concatenate(offsets, axis=0)\nseq_ids = np.concatenate(seq_ids, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:43:18.251294Z","iopub.execute_input":"2022-02-15T04:43:18.25185Z","iopub.status.idle":"2022-02-15T04:43:18.391331Z","shell.execute_reply.started":"2022-02-15T04:43:18.251811Z","shell.execute_reply":"2022-02-15T04:43:18.390536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"location_preds = get_location_predictions(preds, offsets, seq_ids, test=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:43:22.467394Z","iopub.execute_input":"2022-02-15T04:43:22.467991Z","iopub.status.idle":"2022-02-15T04:43:22.486548Z","shell.execute_reply.started":"2022-02-15T04:43:22.467953Z","shell.execute_reply":"2022-02-15T04:43:22.485852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(location_preds), len(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:43:24.683747Z","iopub.execute_input":"2022-02-15T04:43:24.684313Z","iopub.status.idle":"2022-02-15T04:43:24.690863Z","shell.execute_reply.started":"2022-02-15T04:43:24.684272Z","shell.execute_reply":"2022-02-15T04:43:24.689946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"location\"] = location_preds","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:43:26.979602Z","iopub.execute_input":"2022-02-15T04:43:26.980157Z","iopub.status.idle":"2022-02-15T04:43:26.98502Z","shell.execute_reply.started":"2022-02-15T04:43:26.980118Z","shell.execute_reply":"2022-02-15T04:43:26.984202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[[\"id\", \"location\"]].to_csv(\"submission.csv\", index = False)\npd.read_csv(\"submission.csv\").head()","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:43:29.07465Z","iopub.execute_input":"2022-02-15T04:43:29.074938Z","iopub.status.idle":"2022-02-15T04:43:29.093071Z","shell.execute_reply.started":"2022-02-15T04:43:29.07489Z","shell.execute_reply":"2022-02-15T04:43:29.092348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Special Credits\n- [tomohiroh](https://www.kaggle.com/tomohiroh/nbme-bert-for-beginners)\n- [gazu468](https://www.kaggle.com/gazu468/nbme-details-eda)\n","metadata":{}}]}